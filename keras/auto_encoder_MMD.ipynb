{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ae_models import ae_model\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from keras.layers import Input,Dense,Dropout\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num=10\n",
    "trainx=pd.read_csv(f'../data/CRWU/x_1750_{class_num}_f.csv').iloc[:4000]\n",
    "trainy=pd.read_csv(f'../data/CRWU/y_1750_{class_num}.csv').iloc[:4000]\n",
    "#x_test=pd.read_csv('../data/JN/x_600_2_f.csv').iloc[:3000].values\n",
    "#y_test=pd.read_csv('../data/JN/y_600_2.csv').iloc[:3000].values\n",
    "x_test=pd.read_csv(f'../data/CRWU/x_1772_{class_num}_f.csv').iloc[:4000].values\n",
    "y_test=pd.read_csv(f'../data/CRWU/y_1772_{class_num}.csv').iloc[:4000].values\n",
    "index =list(trainx.index)\n",
    "random.Random(0).shuffle(index)\n",
    "num=int(len(index)/5*5)\n",
    "x_train,y_train=trainx.iloc[index[:num],:].values,trainy.iloc[index[:num],:].values\n",
    "#x_test,y_test=trainx.iloc[index[num:],:].values,trainy.iloc[index[num:],:].values\n",
    "#标准化处理\n",
    "def trans(data):\n",
    "    nm=np.zeros(data.shape)\n",
    "    for i in range(len(data)):\n",
    "        nm[i,:]=(data[i,:])/np.max(data[i,:])\n",
    "    return nm\n",
    "x_train=trans(x_train)\n",
    "x_test=trans(x_test)\n",
    "data_X=np.vstack([x_train,x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## contractive auto-encoder\n",
    "lam=10e-5\n",
    "def contractive_loss(y_pred, y_true):\n",
    "    mse = K.mean(K.square(y_true - y_pred), axis=1)\n",
    "    contractive=0\n",
    "    for ename in ['eh1','eh2']:\n",
    "        W = K.variable(value=ae_mode.get_layer(ename).get_weights()[0])  # N x N_hidden\n",
    "        W = K.transpose(W)  # N_hidden x N\n",
    "        h = ae_mode.get_layer(ename).output\n",
    "        dh = h * (1 - h)  # N_batch x N_hidden\n",
    "        contractive+= lam * K.sum(dh**2 * K.sum(W**2, axis=1), axis=1)\n",
    "    return mse + contractive\n",
    "#定义损失函数2（默认为categorical_crossentropy）\n",
    "def contractive_loss2(y_pred, y_true):\n",
    "    cost = K.categorical_crossentropy(y_true,y_pred)\n",
    "    contractive=0\n",
    "    for ename in ['eh0','eh1','LR']:\n",
    "        W = K.variable(value=encoder_mode.get_layer(ename).get_weights()[0])  # N x N_hidden\n",
    "        W = K.transpose(W)  # N_hidden x N\n",
    "        h = encoder_mode.get_layer(ename).output\n",
    "        dh = h * (1 - h)  # N_batch x N_hidden\n",
    "        contractive+= lam * K.sum(dh**2 * K.sum(W**2, axis=1), axis=1)\n",
    "    return cost + contractive\n",
    "\n",
    "## non-negetive-constrain\n",
    "l_non=1e-3\n",
    "def non_con(y_pred, y_true):\n",
    "    mse = K.mean(K.square(y_true - y_pred), axis=1)\n",
    "    non_constrain=0\n",
    "    for ename in ['eh0','eh1']:\n",
    "        weights = K.variable(value=ae_mode.get_layer(ename).get_weights()[0]) # N x N_hidden\n",
    "        non_constrain+= (K.sum(K.abs(weights))-K.sum(K.abs(weights)))**2\n",
    "    return mse + non_constrain*l_non\n",
    "#定义损失函数2（默认为categorical_crossentropy）\n",
    "def non_con2(y_pred, y_true):\n",
    "    cost = K.categorical_crossentropy(y_true,y_pred)\n",
    "    non_constrain=0\n",
    "    for ename in ['eh0','eh1','LR']:\n",
    "        W = K.variable(value=encoder_mode.get_layer(ename).get_weights()[0])  # N x N_hidden\n",
    "        non_constrain+= (K.sum(K.abs(weights))-K.sum(K.abs(weights)))**2\n",
    "    return cost + non_constrain*l_non\n",
    "\n",
    "### MMD\n",
    "def compute_kernel(x, y):\n",
    "    x_size = K.shape(x)[0]\n",
    "    y_size = K.shape(y)[0]\n",
    "    dim = K.shape(x)[1]\n",
    "    tiled_x = K.tile(K.reshape(x, [x_size, 1, dim]), [1, y_size, 1])\n",
    "    tiled_y = K.tile(K.reshape(y, [1, y_size, dim]), [x_size, 1, 1])\n",
    "    return K.exp(-K.mean(K.square(tiled_x - tiled_y), axis=2) / K.cast(dim, 'float32'))\n",
    "\n",
    "def compute_mmd(x, y):\n",
    "    x_kernel = compute_kernel(x, x)\n",
    "    y_kernel = compute_kernel(y, y)\n",
    "    xy_kernel = compute_kernel(x, y)\n",
    "    return K.mean(x_kernel) + K.mean(y_kernel) - 2 * K.mean(xy_kernel)\n",
    "\n",
    "def custom_loss(encode_t,encode_s,ae_out,train_xr):\n",
    "\n",
    "    loss_mmd = compute_mmd(encode_t,encode_s)\n",
    "    'Then, also get the reconstructed loss'\n",
    "    loss_nll = K.mean(K.square(train_xr - ae_out))\n",
    "    loss = loss_nll + loss_mmd*0.1\n",
    "    return loss\n",
    "def custom_loss2(encode_s,encode_t,LR,y_true):\n",
    "    loss_mmd = compute_mmd(encode_t,encode_s)\n",
    "    'Then, also get the reconstructed loss'\n",
    "    loss_cost = K.categorical_crossentropy(y_true,LR)\n",
    "    loss = loss_cost + loss_mmd*0.1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_utils.py:819: UserWarning: Output dense_4 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to dense_4.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 3s 682us/step - loss: 5.3488\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 1s 130us/step - loss: 1.2658\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 1s 130us/step - loss: 0.3268\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 1s 133us/step - loss: 0.1054\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 1s 129us/step - loss: 0.0403\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 1s 141us/step - loss: 0.0190\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 1s 129us/step - loss: 0.0117\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 1s 136us/step - loss: 0.0091\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 1s 132us/step - loss: 0.0085\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 1s 130us/step - loss: 0.0080\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "#第一个input\n",
    "input_dim=1024\n",
    "input_s=Input(shape=(input_dim,))\n",
    "input_t=Input(shape=(input_dim,))\n",
    "\n",
    "ae=ae_model(input_dim,[400,200,64],0.1,0.01,0)\n",
    "ae_out=ae.auto_encode(input_s)\n",
    "encode_t=ae.encode(input_t)\n",
    "\n",
    "#分类\n",
    "encode_s=ae.encode(input_s)\n",
    "LR=Dense(class_num,activation='softmax',name='LR')(encode_s)\n",
    "\n",
    "#编译自编码\n",
    "ae_mode=Model(inputs=[input_s,input_t],outputs=ae_out)\n",
    "loss = custom_loss(encode_s,encode_t,ae_out,input_s)\n",
    "ae_mode.add_loss(loss)\n",
    "ae_mode.compile(optimizer='adam')\n",
    "hist=ae_mode.fit([x_train,x_test],epochs=10,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\keras\\engine\\training_utils.py:819: UserWarning: Output LR missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to LR.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4000/4000 [==============================] - 1s 339us/step - loss: 7.0457\n",
      "Epoch 2/50\n",
      "4000/4000 [==============================] - 1s 142us/step - loss: 2.4730\n",
      "Epoch 3/50\n",
      "4000/4000 [==============================] - 1s 145us/step - loss: 1.2328\n",
      "Epoch 4/50\n",
      "4000/4000 [==============================] - 1s 153us/step - loss: 0.8059\n",
      "Epoch 5/50\n",
      "4000/4000 [==============================] - 1s 150us/step - loss: 0.6075\n",
      "Epoch 6/50\n",
      "4000/4000 [==============================] - 1s 147us/step - loss: 0.5074\n",
      "Epoch 7/50\n",
      "4000/4000 [==============================] - 1s 145us/step - loss: 0.4462\n",
      "Epoch 8/50\n",
      "4000/4000 [==============================] - 1s 150us/step - loss: 0.3992\n",
      "Epoch 9/50\n",
      "4000/4000 [==============================] - 1s 147us/step - loss: 0.3698\n",
      "Epoch 10/50\n",
      "4000/4000 [==============================] - 1s 145us/step - loss: 0.3474\n",
      "Epoch 11/50\n",
      "4000/4000 [==============================] - 1s 145us/step - loss: 0.3309\n",
      "Epoch 12/50\n",
      "4000/4000 [==============================] - 1s 144us/step - loss: 0.3184\n",
      "Epoch 13/50\n",
      "4000/4000 [==============================] - 1s 145us/step - loss: 0.3062\n",
      "Epoch 14/50\n",
      "4000/4000 [==============================] - 1s 144us/step - loss: 0.2938\n",
      "Epoch 15/50\n",
      "4000/4000 [==============================] - 1s 143us/step - loss: 0.2863\n",
      "Epoch 16/50\n",
      "4000/4000 [==============================] - 1s 144us/step - loss: 0.2770\n",
      "Epoch 17/50\n",
      "4000/4000 [==============================] - 1s 143us/step - loss: 0.2721\n",
      "Epoch 18/50\n",
      "4000/4000 [==============================] - 1s 147us/step - loss: 0.2645\n",
      "Epoch 19/50\n",
      "4000/4000 [==============================] - 1s 146us/step - loss: 0.2621\n",
      "Epoch 20/50\n",
      "4000/4000 [==============================] - 1s 143us/step - loss: 0.2556\n",
      "Epoch 21/50\n",
      "4000/4000 [==============================] - 1s 143us/step - loss: 0.2525\n",
      "Epoch 22/50\n",
      "4000/4000 [==============================] - 1s 146us/step - loss: 0.2478\n",
      "Epoch 23/50\n",
      "4000/4000 [==============================] - 1s 155us/step - loss: 0.2421\n",
      "Epoch 24/50\n",
      "4000/4000 [==============================] - 1s 155us/step - loss: 0.2363\n",
      "Epoch 25/50\n",
      "4000/4000 [==============================] - 1s 148us/step - loss: 0.2325\n",
      "Epoch 26/50\n",
      "4000/4000 [==============================] - 1s 140us/step - loss: 0.2277\n",
      "Epoch 27/50\n",
      "4000/4000 [==============================] - 1s 163us/step - loss: 0.2272\n",
      "Epoch 28/50\n",
      "4000/4000 [==============================] - 1s 140us/step - loss: 0.2231\n",
      "Epoch 29/50\n",
      "4000/4000 [==============================] - 1s 144us/step - loss: 0.2209\n",
      "Epoch 30/50\n",
      "4000/4000 [==============================] - 1s 143us/step - loss: 0.2218\n",
      "Epoch 31/50\n",
      "4000/4000 [==============================] - 1s 142us/step - loss: 0.2179\n",
      "Epoch 32/50\n",
      "4000/4000 [==============================] - 1s 143us/step - loss: 0.2139\n",
      "Epoch 33/50\n",
      "4000/4000 [==============================] - 1s 148us/step - loss: 0.2098\n",
      "Epoch 34/50\n",
      "4000/4000 [==============================] - 1s 144us/step - loss: 0.2071\n",
      "Epoch 35/50\n",
      "4000/4000 [==============================] - 1s 153us/step - loss: 0.2064\n",
      "Epoch 36/50\n",
      "4000/4000 [==============================] - 1s 146us/step - loss: 0.2019\n",
      "Epoch 37/50\n",
      "4000/4000 [==============================] - 1s 150us/step - loss: 0.1975\n",
      "Epoch 38/50\n",
      "4000/4000 [==============================] - 1s 144us/step - loss: 0.1999\n",
      "Epoch 39/50\n",
      "4000/4000 [==============================] - 1s 143us/step - loss: 0.1986\n",
      "Epoch 40/50\n",
      "4000/4000 [==============================] - 1s 157us/step - loss: 0.1965\n",
      "Epoch 41/50\n",
      "4000/4000 [==============================] - 1s 156us/step - loss: 0.1922\n",
      "Epoch 42/50\n",
      "4000/4000 [==============================] - 1s 144us/step - loss: 0.1891\n",
      "Epoch 43/50\n",
      "4000/4000 [==============================] - 1s 145us/step - loss: 0.1880\n",
      "Epoch 44/50\n",
      "4000/4000 [==============================] - 1s 152us/step - loss: 0.1863\n",
      "Epoch 45/50\n",
      "4000/4000 [==============================] - 1s 151us/step - loss: 0.2006\n",
      "Epoch 46/50\n",
      "4000/4000 [==============================] - 1s 150us/step - loss: 0.1879\n",
      "Epoch 47/50\n",
      "4000/4000 [==============================] - 1s 143us/step - loss: 0.1883\n",
      "Epoch 48/50\n",
      "4000/4000 [==============================] - 1s 144us/step - loss: 0.1904\n",
      "Epoch 49/50\n",
      "4000/4000 [==============================] - 1s 144us/step - loss: 0.1855\n",
      "Epoch 50/50\n",
      "4000/4000 [==============================] - 1s 146us/step - loss: 0.1928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17b3ec85808>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true=Input(shape=(class_num,))\n",
    "encoder_mode=Model(inputs=[input_s,input_t,y_true],outputs=LR)\n",
    "loss = custom_loss2(encode_s,encode_t,LR,y_true)\n",
    "encoder_mode.add_loss(loss)\n",
    "encoder_mode.compile(optimizer='adam',metrics=['categorical_accuracy'])\n",
    "encoder_mode.fit([x_train,x_test,y_train],epochs=50,batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Model(inputs=input_s,outputs=LR)\n",
    "c=pred.predict(x_test)\n",
    "np.mean(np.where(c.argmax(axis=1)==y_test.argmax(axis=1),1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mmd2(Z):\n",
    "    x=Z[0]\n",
    "    y=Z[1]\n",
    "    x_kernel = compute_kernel(x, x)\n",
    "    y_kernel = compute_kernel(y, y)\n",
    "    xy_kernel = compute_kernel(x, y)\n",
    "    return K.mean(x_kernel) + K.mean(y_kernel) - 2 * K.mean(xy_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算mmd\n",
    "from keras.layers import Lambda\n",
    "inp=Input(shape=(input_dim,))\n",
    "encoder_=ae.encode(inp)\n",
    "emode=Model(inp,encoder_)\n",
    "\n",
    "input_s=Input(shape=(input_dim,))\n",
    "input_t=Input(shape=(input_dim,))\n",
    "encode1=emode(input_s)\n",
    "encode2=emode(input_t)\n",
    "out_mmd=Lambda(compute_mmd2)([encode1,encode2])\n",
    "mmd_cost=Model(inputs=[input_s,input_t],outputs=out_mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_s=encoder_data()\n",
    "input_t=encoder_data()\n",
    "inp1=input_s.input\n",
    "inp2=input_t.input\n",
    "for layer in input_s.layers:\n",
    "    layer.name =layer.name + str(\"_2\")\n",
    "\n",
    "out_mmd=Lambda(compute_mmd2)([input_s.output,input_t.output])\n",
    "mmd_cost=Model(inputs=[inp1,inp2],outputs=out_mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0994415e-06, 3.0994415e-06, 3.0994415e-06, 3.0994415e-06,\n",
       "       3.0994415e-06, 3.0994415e-06, 3.0994415e-06, 3.0994415e-06,\n",
       "       3.0994415e-06, 3.0994415e-06, 3.0994415e-06, 3.0994415e-06,\n",
       "       3.0994415e-06, 3.0994415e-06, 3.0994415e-06, 3.0994415e-06,\n",
       "       3.0994415e-06, 3.0994415e-06, 3.0994415e-06, 3.0994415e-06,\n",
       "       3.0994415e-06, 3.0994415e-06, 3.0994415e-06, 3.0994415e-06,\n",
       "       3.0994415e-06, 3.0994415e-06, 3.0994415e-06, 3.0994415e-06,\n",
       "       3.0994415e-06, 3.0994415e-06, 3.0994415e-06, 3.0994415e-06,\n",
       "       5.7220459e-06, 5.7220459e-06, 5.7220459e-06, 5.7220459e-06,\n",
       "       5.7220459e-06, 5.7220459e-06, 5.7220459e-06, 5.7220459e-06,\n",
       "       5.7220459e-06, 5.7220459e-06, 5.7220459e-06, 5.7220459e-06,\n",
       "       5.7220459e-06, 5.7220459e-06, 5.7220459e-06, 5.7220459e-06,\n",
       "       5.7220459e-06, 5.7220459e-06], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd_cost.predict([x_test[:50],x_train[:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score=encoder_mode.evaluate([x_train,x_test,y_train])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
